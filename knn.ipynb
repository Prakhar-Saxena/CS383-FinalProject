{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "io17fEWEARSG"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from numpy import dot as dot\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import math\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YCRpg7D7ARSg"
   },
   "outputs": [],
   "source": [
    "def modify_data(df):\n",
    "    for feature_split in feature_modifications:\n",
    "        df = feature_split(df)\n",
    "    x = df[feature_cols]\n",
    "    full_cols = feature_cols[:]\n",
    "    full_cols.append('Category')\n",
    "    print(feature_cols)\n",
    "    df_ = df[full_cols]\n",
    "    y = output_col_mod(df)\n",
    "    return x, y, df_\n",
    "\n",
    "def date_time_split(df):\n",
    "    def time_in_mins_since_midnight(time):\n",
    "        return (time.hour * 60) + time.minute\n",
    "\n",
    "    df['Time'] = pd.to_datetime(df['Dates']).dt.time.map(time_in_mins_since_midnight)\n",
    "\n",
    "    def time_bin(hour):\n",
    "        for bin_ in time_bins:\n",
    "            if hour < bin_:\n",
    "                return time_bins[bin_]\n",
    "\n",
    "    df['Time_Class'] = pd.to_datetime(df['Dates']).dt.hour.map(time_bin)\n",
    "    return df\n",
    "\n",
    "def day_map(df):\n",
    "    df = df.replace({\"DayOfWeek\": day_mapping})\n",
    "    return df\n",
    "\n",
    "def round_xy(df):\n",
    "    if 'X' in feature_cols:\n",
    "        df = df.round({'X': 2})\n",
    "    if 'Y' in feature_cols:\n",
    "        df = df.round({'Y': 2})\n",
    "    return df\n",
    "\n",
    "def drop_na(df):\n",
    "    return df.dropna(subset=feature_cols)\n",
    "\n",
    "# Modify Category to only include the top 5 most common crime categories \n",
    "# and everything else as other. Then assign values to each\n",
    "def output_col_mod(df):\n",
    "    df = df[['Category']]\n",
    "    cols = output_col_mapping.keys()\n",
    "    df = df.Category.map(output_col_mapping).fillna(output_col_mapping[\"OTHER OFFENSES\"]).astype(int)\n",
    "    df = df.to_frame().reset_index()\n",
    "    df = df[['Category']]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LOIHdsRsARS5"
   },
   "outputs": [],
   "source": [
    "dataset_dir = '../CS383_datasets/'\n",
    "\n",
    "# Include any columns that might be produced as a result of any feature modification functions\n",
    "# All columns will be numeric and this is being enforced\n",
    "# X and Y will be automatically rounded if in feature_cols\n",
    "# Drop_na should always be run last in feature modifications\n",
    "feature_cols = ['Time', 'Time_Class', 'DayOfWeek', 'X', 'Y']\n",
    "feature_modifications = [\n",
    "    date_time_split,\n",
    "    day_map,\n",
    "    round_xy,\n",
    "    drop_na\n",
    "]\n",
    "\n",
    "\n",
    "output_col = 'Category'\n",
    "\n",
    "# How many different classifications to make?\n",
    "output_col_mapping = {\n",
    "    'LARCENY/THEFT': 0, \n",
    "    'NON-CRIMINAL': 1, \n",
    "    'ASSAULT': 2,\n",
    "    'DRUG/NARCOTIC': 3,\n",
    "    'VEHICLE THEFT': 4,\n",
    "#     Includes other offenses and all offenses not included above\n",
    "    'OTHER OFFENSES': 5,\n",
    "}\n",
    "\n",
    "# {'LARCENY/THEFT': 174900, 'OTHER OFFENSES': 126182, 'NON-CRIMINAL': 92304, 'ASSAULT': 76876, \n",
    "# 'DRUG/NARCOTIC': 53971, 'VEHICLE THEFT': 53781, 'VANDALISM': 44725, 'WARRANTS': 42214, \n",
    "# 'BURGLARY': 36755, 'SUSPICIOUS OCC': 31414, 'MISSING PERSON': 25989, 'ROBBERY': 23000, \n",
    "# 'FRAUD': 16679, 'FORGERY/COUNTERFEITING': 10609, 'SECONDARY CODES': 9985, 'WEAPON LAWS': 8555, \n",
    "# 'PROSTITUTION': 7484, 'TRESPASS': 7326, 'STOLEN PROPERTY': 4540, 'SEX OFFENSES FORCIBLE': 4388, \n",
    "# 'DISORDERLY CONDUCT': 4320, 'DRUNKENNESS': 4280, 'RECOVERED VEHICLE': 3138, 'KIDNAPPING': 2341, \n",
    "# 'DRIVING UNDER THE INFLUENCE': 2268, 'RUNAWAY': 1946, 'LIQUOR LAWS': 1903, 'ARSON': 1513, \n",
    "# 'LOITERING': 1225, 'EMBEZZLEMENT': 1166, 'SUICIDE': 508, 'FAMILY OFFENSES': 491, 'BAD CHECKS': 406, \n",
    "# 'BRIBERY': 289, 'EXTORTION': 256, 'SEX OFFENSES NON FORCIBLE': 148, 'GAMBLING': 146, \n",
    "# 'PORNOGRAPHY/OBSCENE MAT': 22, 'TREA': 6}\n",
    "\n",
    "\n",
    "# Keys are evaluated as: hour is less than key\n",
    "# Cycle runs from midnight 00:00 to 23:59\n",
    "time_bins = {\n",
    "    4: 0, # Before 4am is 0\n",
    "    6: 1, # Before 6am is 1\n",
    "    12: 2, # Before 12pm is 2\n",
    "    18: 3, # Before 4pm is 3\n",
    "    24: 4, # Before midnight is 4\n",
    "}\n",
    "\n",
    "day_mapping = {\n",
    "    'Sunday': 0,\n",
    "    'Monday': 1,\n",
    "    'Tuesday': 2,\n",
    "    'Wednesday': 3,\n",
    "    'Thursday': 4,\n",
    "    'Friday': 5,\n",
    "    'Saturday': 6,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ipQjQVLxARTL"
   },
   "outputs": [],
   "source": [
    "def test_train_split(x, y, shuffle=True, test_size=0.2):\n",
    "    return train_test_split(x, y, test_size=test_size, random_state=0, shuffle=shuffle)\n",
    "\n",
    "# Standardize by subtracting column mean and divide by the standard deviation of the column\n",
    "def standardize_data(training_data, testing_data=None):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(training_data.to_numpy())\n",
    "    training_data = scaler.transform(training_data.to_numpy())\n",
    "    testing_data = scaler.transform(testing_data.to_numpy())\n",
    "    \n",
    "    return training_data, testing_data\n",
    "\n",
    "# Prepare and Get test train data\n",
    "def get_data():\n",
    "    # Fixing random state for reproducibility\n",
    "    np.random.seed(0)\n",
    "\n",
    "    train = pd.read_csv(dataset_dir + 'train.csv')\n",
    "\n",
    "    x, y, df = modify_data(train)\n",
    "\n",
    "    X_train, X_test, y_train, y_test = test_train_split(x, y)\n",
    "\n",
    "    # Standardize training and testing data using training\n",
    "    # (Feature columns only)\n",
    "    X_train, X_test = standardize_data(X_train, X_test)\n",
    "\n",
    "    # Fixing random state for reproducibility again cause optional preparation steps\n",
    "    # might have random steps\n",
    "    np.random.seed(0)\n",
    "\n",
    "    return X_train, X_test, y_train.to_numpy(), y_test.to_numpy(), df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ml_AnboSARTa"
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test, df = get_data()\n",
    "# df is pandas dataframe before standardizing data\n",
    "# y_test and X_test are Category data and style can be found above\n",
    "# X_train and y_train cols are feature cols in the order\n",
    "# Currently Feature Cols are: ['Time', 'Time_Class', 'DayOfWeek', 'X', 'Y']\n",
    "print(X_train)\n",
    "print(X_test)\n",
    "print(y_train)\n",
    "print(y_test)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DXImfrdjsoYH"
   },
   "outputs": [],
   "source": [
    "X_test_sub = X_test[:1000,:]  #test subset for sklearn knn\n",
    "y_test_sub = y_test[:1000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXflUYBGLVwR"
   },
   "outputs": [],
   "source": [
    "trainset = np.append(X_train,y_train,axis=1)\n",
    "testset=np.append(X_test_sub,y_test_sub,axis=1) ##test subset for our knn (above X_test_sub and his having same data )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "IsDLHSuoE-z7"
   },
   "source": [
    "## Finding best k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pAm6L4HXwQXb"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "# Creating odd list K for KNN\n",
    "neighbors = list(range(1,50,2))\n",
    "# empty list that will hold cv scores\n",
    "cv_scores = [ ]\n",
    "#perform 10-fold cross-validation\n",
    "for K in neighbors:\n",
    "    knn = KNeighborsClassifier(n_neighbors = K)\n",
    "    scores = cross_val_score(knn,X_train,y_train,cv = 10,scoring =\n",
    "    \"accuracy\")\n",
    "    cv_scores.append(scores.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W7N-vy-kxVFL"
   },
   "outputs": [],
   "source": [
    "# Changing to mis classification error\n",
    "mse = [1-x for x in cv_scores]\n",
    "# determing best k\n",
    "optimal_k = neighbors[mse.index(min(mse))]\n",
    "print(\"The optimal no. of neighbors is {}\".format(optimal_k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V5acK8e7xe-t"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(neighbors, mse)\n",
    "plt.xlabel(\"Number of Neighbors K\")\n",
    "plt.ylabel(\"Misclassification Error\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0885QVWCFMm6"
   },
   "source": [
    "# Knn from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bfKLvVmOBFaE"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# instantiate learning model (k = 3)\n",
    "knn = KNeighborsClassifier(n_neighbors=10)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test_sub)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(\"accuracy: {}\".format(accuracy_score(y_test_sub, pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4LD0PqlRBo4T"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# instantiate learning model (k = 49)\n",
    "knn = KNeighborsClassifier(n_neighbors=49)\n",
    "\n",
    "# fitting the model\n",
    "knn.fit(X_train, y_train)\n",
    "\n",
    "# predict the response\n",
    "pred = knn.predict(X_test_sub)\n",
    "\n",
    "# evaluate accuracy\n",
    "print(\"accuracy: {}\".format(accuracy_score(y_test_sub, pred)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Wq_uzeT6FZSh"
   },
   "source": [
    "# our Knn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "V8dqY6H3JKa3"
   },
   "outputs": [],
   "source": [
    "#Define Euclidean distances\n",
    "import math\n",
    "def Euclideandist(x,xi, length):\n",
    "    d = 0.0\n",
    "    for i in range(length):\n",
    "        d += pow(float(x[i])- float(xi[i]),2)\n",
    "    return math.sqrt(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v05suRniKn4w"
   },
   "outputs": [],
   "source": [
    "#Getting the K neighbours having the closest Euclidean distance to the test instance\n",
    "import operator\n",
    "def getNeighbors(trainingSet, testInstance, k):\n",
    "    distances = []\n",
    "    length = len(testInstance)-1\n",
    "    for x in range(len(trainingSet)):\n",
    "        dist = Euclideandist(testInstance, trainingSet[x], length)\n",
    "        distances.append((trainingSet[x], dist))\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dqUDavNlKqiD"
   },
   "outputs": [],
   "source": [
    "#After sorting the neighbours based on their respective classes, max voting to give the final class of the test instance\n",
    "def getResponse(neighbors):\n",
    "\tclassVotes = {}\n",
    "\tfor x in range(len(neighbors)):\n",
    "\t\tresponse = neighbors[x][-1]\n",
    "\t\tif response in classVotes:\n",
    "\t\t\tclassVotes[response] += 1\n",
    "\t\telse:\n",
    "\t\t\tclassVotes[response] = 1\n",
    "\tsortedVotes = sorted(classVotes.items(), key=operator.itemgetter(1), reverse=True)#Sorting it based on votes\n",
    "\treturn sortedVotes[0][0]#Please note we need the class for the top voted class, hence [0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LMPQkBshLoeO"
   },
   "outputs": [],
   "source": [
    "\n",
    "#Getting the accuracy\n",
    "def getAccuracy(testSet, predictions):\n",
    "\tcorrect = 0\n",
    "\tfor x in range(len(testSet)):\n",
    "\t\tif testSet[x][-1] == predictions[x]:\n",
    "\t\t\tcorrect += 1\n",
    "\treturn (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3d-eVAkqKxWt"
   },
   "outputs": [],
   "source": [
    "# generate predictions\n",
    "#it will take long time depending upon test datasize\n",
    "predictions=[]\n",
    "k = 49\n",
    "for x in range(len(testset)):\n",
    "    neighbors = getNeighbors(trainset, testset[x], k)\n",
    "    result = getResponse(neighbors)\n",
    "    predictions.append(result)\n",
    "    print('> predicted=' + repr(result) + ', actual=' + repr(testset[x][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h0Hhm9qtLFCl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "accuracy = getAccuracy(y_test_sub, predictions)\n",
    "print('Accuracy: ' + repr(accuracy) + '%')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ArRKB91nMAAQ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of knn.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
